{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bilal\\AppData\\Local\\Temp\\ipykernel_14524\\3423587815.py:9: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  features_df = pd.read_csv(\"features.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load features from CSV file\n",
    "features_df = pd.read_csv(\"features.csv\")\n",
    "\n",
    "# Convert all columns to strings\n",
    "features_df = features_df.astype(str)\n",
    "\n",
    "# Convert categorical data to numerical data\n",
    "label_encoder = LabelEncoder()\n",
    "for column in features_df.columns:\n",
    "    features_df[column] = label_encoder.fit_transform(features_df[column])\n",
    "\n",
    "# Check if there are any numeric features\n",
    "numeric_features_df = features_df.select_dtypes(include=[np.number])\n",
    "if numeric_features_df.empty:\n",
    "    print(\"No numeric features found in the dataset.\")\n",
    "else:\n",
    "    # Separate the features from the dataframe\n",
    "    features = numeric_features_df.values\n",
    "\n",
    "    # Normalization\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_features = scaler.fit_transform(features)\n",
    "\n",
    "    # Standardization\n",
    "    scaler = StandardScaler()\n",
    "    standardized_features = scaler.fit_transform(features)\n",
    "\n",
    "    # Dimensionality reduction (PCA)\n",
    "    pca = PCA(n_components=5)  # Assuming you want to reduce to 5 dimensions\n",
    "    reduced_features = pca.fit_transform(features)\n",
    "\n",
    "    # Combine all transformed features into a single DataFrame\n",
    "    transformed_df = pd.DataFrame(normalized_features, columns=[f\"Normalized_Feature_{i}\" for i in range(normalized_features.shape[1])])\n",
    "    transformed_df = transformed_df.join(pd.DataFrame(standardized_features, columns=[f\"Standardized_Feature_{i}\" for i in range(standardized_features.shape[1])]))\n",
    "    transformed_df = transformed_df.join(pd.DataFrame(reduced_features, columns=[f\"Reduced_Component_{i}\" for i in range(reduced_features.shape[1])]))\n",
    "\n",
    "    # Save the transformed features to a single CSV file\n",
    "    transformed_df.to_csv(\"transformed_features.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>chroma_cens</th>\n",
       "      <th>chroma_cens.1</th>\n",
       "      <th>chroma_cens.2</th>\n",
       "      <th>chroma_cens.3</th>\n",
       "      <th>chroma_cens.4</th>\n",
       "      <th>chroma_cens.5</th>\n",
       "      <th>chroma_cens.6</th>\n",
       "      <th>chroma_cens.7</th>\n",
       "      <th>chroma_cens.8</th>\n",
       "      <th>...</th>\n",
       "      <th>tonnetz.39</th>\n",
       "      <th>tonnetz.40</th>\n",
       "      <th>tonnetz.41</th>\n",
       "      <th>zcr</th>\n",
       "      <th>zcr.1</th>\n",
       "      <th>zcr.2</th>\n",
       "      <th>zcr.3</th>\n",
       "      <th>zcr.4</th>\n",
       "      <th>zcr.5</th>\n",
       "      <th>zcr.6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106575</td>\n",
       "      <td>104375</td>\n",
       "      <td>104380</td>\n",
       "      <td>104388</td>\n",
       "      <td>104393</td>\n",
       "      <td>104408</td>\n",
       "      <td>104377</td>\n",
       "      <td>104388</td>\n",
       "      <td>104382</td>\n",
       "      <td>104373</td>\n",
       "      <td>...</td>\n",
       "      <td>104170</td>\n",
       "      <td>103962</td>\n",
       "      <td>103954</td>\n",
       "      <td>104378</td>\n",
       "      <td>2582</td>\n",
       "      <td>104217</td>\n",
       "      <td>1152</td>\n",
       "      <td>213</td>\n",
       "      <td>104320</td>\n",
       "      <td>104272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106574</td>\n",
       "      <td>88275</td>\n",
       "      <td>89860</td>\n",
       "      <td>87670</td>\n",
       "      <td>89427</td>\n",
       "      <td>89094</td>\n",
       "      <td>88132</td>\n",
       "      <td>88809</td>\n",
       "      <td>87624</td>\n",
       "      <td>89339</td>\n",
       "      <td>...</td>\n",
       "      <td>103147</td>\n",
       "      <td>102938</td>\n",
       "      <td>102931</td>\n",
       "      <td>11205</td>\n",
       "      <td>1912</td>\n",
       "      <td>103193</td>\n",
       "      <td>920</td>\n",
       "      <td>174</td>\n",
       "      <td>16350</td>\n",
       "      <td>103249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106576</td>\n",
       "      <td>104376</td>\n",
       "      <td>104381</td>\n",
       "      <td>104389</td>\n",
       "      <td>104394</td>\n",
       "      <td>104409</td>\n",
       "      <td>104378</td>\n",
       "      <td>104389</td>\n",
       "      <td>104383</td>\n",
       "      <td>104374</td>\n",
       "      <td>...</td>\n",
       "      <td>104169</td>\n",
       "      <td>103961</td>\n",
       "      <td>103953</td>\n",
       "      <td>104379</td>\n",
       "      <td>2583</td>\n",
       "      <td>104218</td>\n",
       "      <td>1153</td>\n",
       "      <td>214</td>\n",
       "      <td>104319</td>\n",
       "      <td>104271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47614</td>\n",
       "      <td>103974</td>\n",
       "      <td>103477</td>\n",
       "      <td>99202</td>\n",
       "      <td>93598</td>\n",
       "      <td>94365</td>\n",
       "      <td>103382</td>\n",
       "      <td>94398</td>\n",
       "      <td>99927</td>\n",
       "      <td>104209</td>\n",
       "      <td>...</td>\n",
       "      <td>103584</td>\n",
       "      <td>102959</td>\n",
       "      <td>102947</td>\n",
       "      <td>80892</td>\n",
       "      <td>2373</td>\n",
       "      <td>104157</td>\n",
       "      <td>1096</td>\n",
       "      <td>1</td>\n",
       "      <td>47676</td>\n",
       "      <td>104133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54358</td>\n",
       "      <td>96661</td>\n",
       "      <td>104091</td>\n",
       "      <td>101531</td>\n",
       "      <td>99456</td>\n",
       "      <td>95723</td>\n",
       "      <td>103879</td>\n",
       "      <td>93337</td>\n",
       "      <td>88442</td>\n",
       "      <td>90467</td>\n",
       "      <td>...</td>\n",
       "      <td>103708</td>\n",
       "      <td>103039</td>\n",
       "      <td>103276</td>\n",
       "      <td>45798</td>\n",
       "      <td>2380</td>\n",
       "      <td>104153</td>\n",
       "      <td>1081</td>\n",
       "      <td>1</td>\n",
       "      <td>34469</td>\n",
       "      <td>104187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106572</th>\n",
       "      <td>44209</td>\n",
       "      <td>26288</td>\n",
       "      <td>79470</td>\n",
       "      <td>98604</td>\n",
       "      <td>3966</td>\n",
       "      <td>95796</td>\n",
       "      <td>98244</td>\n",
       "      <td>11610</td>\n",
       "      <td>103464</td>\n",
       "      <td>86706</td>\n",
       "      <td>...</td>\n",
       "      <td>82433</td>\n",
       "      <td>64073</td>\n",
       "      <td>43086</td>\n",
       "      <td>70800</td>\n",
       "      <td>312</td>\n",
       "      <td>18798</td>\n",
       "      <td>94</td>\n",
       "      <td>9</td>\n",
       "      <td>15414</td>\n",
       "      <td>6574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106573</th>\n",
       "      <td>44210</td>\n",
       "      <td>24724</td>\n",
       "      <td>11443</td>\n",
       "      <td>25910</td>\n",
       "      <td>22388</td>\n",
       "      <td>67434</td>\n",
       "      <td>13280</td>\n",
       "      <td>33917</td>\n",
       "      <td>3773</td>\n",
       "      <td>11426</td>\n",
       "      <td>...</td>\n",
       "      <td>85230</td>\n",
       "      <td>69913</td>\n",
       "      <td>82651</td>\n",
       "      <td>58563</td>\n",
       "      <td>360</td>\n",
       "      <td>22766</td>\n",
       "      <td>92</td>\n",
       "      <td>6</td>\n",
       "      <td>22961</td>\n",
       "      <td>19004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106574</th>\n",
       "      <td>44211</td>\n",
       "      <td>79826</td>\n",
       "      <td>5172</td>\n",
       "      <td>27948</td>\n",
       "      <td>72277</td>\n",
       "      <td>11105</td>\n",
       "      <td>28146</td>\n",
       "      <td>96151</td>\n",
       "      <td>92750</td>\n",
       "      <td>93309</td>\n",
       "      <td>...</td>\n",
       "      <td>66829</td>\n",
       "      <td>28074</td>\n",
       "      <td>47964</td>\n",
       "      <td>42921</td>\n",
       "      <td>394</td>\n",
       "      <td>36088</td>\n",
       "      <td>130</td>\n",
       "      <td>8</td>\n",
       "      <td>12826</td>\n",
       "      <td>16556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106575</th>\n",
       "      <td>44212</td>\n",
       "      <td>8695</td>\n",
       "      <td>70914</td>\n",
       "      <td>2381</td>\n",
       "      <td>75792</td>\n",
       "      <td>64742</td>\n",
       "      <td>44752</td>\n",
       "      <td>41896</td>\n",
       "      <td>80532</td>\n",
       "      <td>34392</td>\n",
       "      <td>...</td>\n",
       "      <td>45709</td>\n",
       "      <td>34039</td>\n",
       "      <td>28768</td>\n",
       "      <td>85594</td>\n",
       "      <td>301</td>\n",
       "      <td>41745</td>\n",
       "      <td>134</td>\n",
       "      <td>11</td>\n",
       "      <td>37282</td>\n",
       "      <td>21425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106576</th>\n",
       "      <td>44214</td>\n",
       "      <td>78187</td>\n",
       "      <td>97551</td>\n",
       "      <td>85271</td>\n",
       "      <td>4908</td>\n",
       "      <td>12526</td>\n",
       "      <td>73513</td>\n",
       "      <td>18917</td>\n",
       "      <td>61351</td>\n",
       "      <td>45170</td>\n",
       "      <td>...</td>\n",
       "      <td>49271</td>\n",
       "      <td>49106</td>\n",
       "      <td>20384</td>\n",
       "      <td>49072</td>\n",
       "      <td>1689</td>\n",
       "      <td>86985</td>\n",
       "      <td>160</td>\n",
       "      <td>10</td>\n",
       "      <td>87047</td>\n",
       "      <td>102243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106577 rows Ã— 519 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature  chroma_cens  chroma_cens.1  chroma_cens.2  chroma_cens.3  \\\n",
       "0        106575       104375         104380         104388         104393   \n",
       "1        106574        88275          89860          87670          89427   \n",
       "2        106576       104376         104381         104389         104394   \n",
       "3         47614       103974         103477          99202          93598   \n",
       "4         54358        96661         104091         101531          99456   \n",
       "...         ...          ...            ...            ...            ...   \n",
       "106572    44209        26288          79470          98604           3966   \n",
       "106573    44210        24724          11443          25910          22388   \n",
       "106574    44211        79826           5172          27948          72277   \n",
       "106575    44212         8695          70914           2381          75792   \n",
       "106576    44214        78187          97551          85271           4908   \n",
       "\n",
       "        chroma_cens.4  chroma_cens.5  chroma_cens.6  chroma_cens.7  \\\n",
       "0              104408         104377         104388         104382   \n",
       "1               89094          88132          88809          87624   \n",
       "2              104409         104378         104389         104383   \n",
       "3               94365         103382          94398          99927   \n",
       "4               95723         103879          93337          88442   \n",
       "...               ...            ...            ...            ...   \n",
       "106572          95796          98244          11610         103464   \n",
       "106573          67434          13280          33917           3773   \n",
       "106574          11105          28146          96151          92750   \n",
       "106575          64742          44752          41896          80532   \n",
       "106576          12526          73513          18917          61351   \n",
       "\n",
       "        chroma_cens.8  ...  tonnetz.39  tonnetz.40  tonnetz.41     zcr  zcr.1  \\\n",
       "0              104373  ...      104170      103962      103954  104378   2582   \n",
       "1               89339  ...      103147      102938      102931   11205   1912   \n",
       "2              104374  ...      104169      103961      103953  104379   2583   \n",
       "3              104209  ...      103584      102959      102947   80892   2373   \n",
       "4               90467  ...      103708      103039      103276   45798   2380   \n",
       "...               ...  ...         ...         ...         ...     ...    ...   \n",
       "106572          86706  ...       82433       64073       43086   70800    312   \n",
       "106573          11426  ...       85230       69913       82651   58563    360   \n",
       "106574          93309  ...       66829       28074       47964   42921    394   \n",
       "106575          34392  ...       45709       34039       28768   85594    301   \n",
       "106576          45170  ...       49271       49106       20384   49072   1689   \n",
       "\n",
       "         zcr.2  zcr.3  zcr.4   zcr.5   zcr.6  \n",
       "0       104217   1152    213  104320  104272  \n",
       "1       103193    920    174   16350  103249  \n",
       "2       104218   1153    214  104319  104271  \n",
       "3       104157   1096      1   47676  104133  \n",
       "4       104153   1081      1   34469  104187  \n",
       "...        ...    ...    ...     ...     ...  \n",
       "106572   18798     94      9   15414    6574  \n",
       "106573   22766     92      6   22961   19004  \n",
       "106574   36088    130      8   12826   16556  \n",
       "106575   41745    134     11   37282   21425  \n",
       "106576   86985    160     10   87047  102243  \n",
       "\n",
       "[106577 rows x 519 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: 000\n",
      "Processing folder: 001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bilal\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing audio\\001\\001486.mp3: \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import concurrent.futures\n",
    "import warnings\n",
    "\n",
    "# Suppress PySoundFile and Audioread warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"PySoundFile failed. Trying audioread instead.\")\n",
    "\n",
    "def extract_features(audio_file, sr=22050, n_mfcc=13):\n",
    "    try:\n",
    "        # Load audio file\n",
    "        y, sr = librosa.load(audio_file, sr=sr)\n",
    "        \n",
    "        # Extract MFCC features\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        \n",
    "        # Compute mean of each MFCC coefficient\n",
    "        mfcc_mean = np.mean(mfcc, axis=1)\n",
    "        \n",
    "        return mfcc_mean\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_file}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to process audio files in parallel\n",
    "def process_audio_files(audio_files):\n",
    "    features = []\n",
    "    for audio_file in audio_files:\n",
    "        mfcc_features = extract_features(audio_file)\n",
    "        if mfcc_features is not None:\n",
    "            file_name = os.path.basename(audio_file)  # Extract file name without path\n",
    "            features.append([file_name, *mfcc_features])\n",
    "    return features\n",
    "\n",
    "# Function to normalize features\n",
    "def normalize_features(features):\n",
    "    # Min-max normalization\n",
    "    normalized_features = (features - features.min()) / (features.max() - features.min())\n",
    "    return normalized_features\n",
    "\n",
    "# Function to standardize features\n",
    "def standardize_features(features):\n",
    "    # Standardization\n",
    "    scaler = StandardScaler()\n",
    "    standardized_features = scaler.fit_transform(features)\n",
    "    return standardized_features\n",
    "\n",
    "# Path to the folder containing subfolders of audio files\n",
    "fma_large_folder = \"audio\"\n",
    "\n",
    "# Initialize an empty list to store features\n",
    "features_list = []\n",
    "\n",
    "# Define the number of threads\n",
    "num_threads = os.cpu_count()\n",
    "\n",
    "# Loop through subfolders in fma_large\n",
    "for folder_name in sorted(os.listdir(fma_large_folder)):\n",
    "    folder_path = os.path.join(fma_large_folder, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        print(\"Processing folder:\", folder_name)\n",
    "        \n",
    "        # List all MP3 files in the current subfolder\n",
    "        mp3_files = [os.path.join(folder_path, file_name) for file_name in sorted(os.listdir(folder_path)) if file_name.endswith(\".mp3\")]\n",
    "        \n",
    "        # Process audio files in parallel using multithreading\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "            results = executor.map(process_audio_files, [mp3_files[i:i + num_threads] for i in range(0, len(mp3_files), num_threads)])\n",
    "        \n",
    "        # Flatten the list of features\n",
    "        for batch in results:\n",
    "            features_list.extend(batch)\n",
    "\n",
    "# Convert features list to DataFrame\n",
    "columns = ['filename'] + [f\"mfcc_{i}\" for i in range(len(features_list[0]) - 1)]\n",
    "features_df = pd.DataFrame(features_list, columns=columns)\n",
    "\n",
    "# Drop any rows with missing values (if any)\n",
    "features_df.dropna(inplace=True)\n",
    "\n",
    "# Separate the filename column\n",
    "file_names = features_df['filename']\n",
    "features_df.drop(columns=['filename'], inplace=True)\n",
    "\n",
    "# Apply normalization and standardization to features (excluding filename column)\n",
    "normalized_features = normalize_features(features_df)\n",
    "standardized_features = standardize_features(normalized_features)\n",
    "\n",
    "# Perform dimensionality reduction using PCA\n",
    "pca = PCA(n_components=10)  # Specify the number of components to keep\n",
    "reduced_features = pca.fit_transform(standardized_features)\n",
    "\n",
    "# Convert reduced features to DataFrame\n",
    "reduced_features_df = pd.DataFrame(reduced_features, columns=[f\"pca_{i}\" for i in range(reduced_features.shape[1])])\n",
    "\n",
    "# Concatenate filename column to reduced features DataFrame\n",
    "reduced_features_df.insert(0, 'filename', file_names)\n",
    "\n",
    "# Save the reduced features DataFrame to a new CSV file\n",
    "reduced_features_df.to_csv(\"reduced_audio_features.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        filename     pca_0     pca_1     pca_2     pca_3     pca_4     pca_5  \\\n",
      "0     000002.mp3 -0.213493 -0.889269  0.300109 -1.396368 -0.202127 -0.782602   \n",
      "1     000003.mp3  0.381634 -0.571499 -0.498397 -0.911051  0.144306 -0.135533   \n",
      "2     000005.mp3  1.516205 -0.187136  0.846741 -1.151169  0.056882 -1.181047   \n",
      "3     000010.mp3 -0.875782 -1.428132  0.076501  0.801126 -0.037359 -0.455641   \n",
      "4     000020.mp3  1.863987  0.421322 -0.032939 -0.049972  0.339171 -0.044254   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "1612  001995.mp3 -0.415149 -0.397714 -0.088522  0.741243 -2.236274  4.584163   \n",
      "1613  001996.mp3 -1.006367 -3.281262  0.643810  0.356301 -0.995869 -0.420045   \n",
      "1614  001997.mp3  0.666179  0.840533  0.375378 -0.177088 -0.941006 -0.638792   \n",
      "1615  001998.mp3 -0.478807  1.101714  0.993000 -0.420857 -0.027245  0.200850   \n",
      "1616  001999.mp3 -1.197815  2.253566  0.047799 -0.086981  0.215302 -0.164473   \n",
      "\n",
      "         pca_6     pca_7     pca_8     pca_9  \n",
      "0     0.427355 -0.378870 -0.206127  0.245418  \n",
      "1    -0.291108  0.238224 -0.190828  0.599719  \n",
      "2    -0.998588  0.692014 -0.193811 -0.372841  \n",
      "3     0.287740 -0.704621 -0.147381  0.342391  \n",
      "4     0.014673 -0.472650 -0.010671 -0.493333  \n",
      "...        ...       ...       ...       ...  \n",
      "1612  1.064353  0.191026  0.069646  1.085470  \n",
      "1613  0.003444  1.725088  0.414698  0.666156  \n",
      "1614 -0.147901  0.232280 -0.264233  0.748876  \n",
      "1615 -0.308253  0.669340  0.328827 -0.006168  \n",
      "1616  0.140565  0.568590 -0.054661  0.379453  \n",
      "\n",
      "[1617 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'path_to_your_csv_file' with the actual path to your CSV file\n",
    "csv_file_path = 'reduced_audio_features.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc_0</th>\n",
       "      <th>pc_1</th>\n",
       "      <th>pc_2</th>\n",
       "      <th>pc_3</th>\n",
       "      <th>pc_4</th>\n",
       "      <th>pc_5</th>\n",
       "      <th>pc_6</th>\n",
       "      <th>pc_7</th>\n",
       "      <th>pc_8</th>\n",
       "      <th>pc_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.775385</td>\n",
       "      <td>-0.512451</td>\n",
       "      <td>-1.398603</td>\n",
       "      <td>0.766013</td>\n",
       "      <td>1.904395</td>\n",
       "      <td>2.087560</td>\n",
       "      <td>-0.067536</td>\n",
       "      <td>-0.661068</td>\n",
       "      <td>0.120825</td>\n",
       "      <td>-0.114971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.742665</td>\n",
       "      <td>-0.478032</td>\n",
       "      <td>2.643861</td>\n",
       "      <td>0.371387</td>\n",
       "      <td>0.475300</td>\n",
       "      <td>-0.785631</td>\n",
       "      <td>-0.154473</td>\n",
       "      <td>-0.638914</td>\n",
       "      <td>-0.206860</td>\n",
       "      <td>0.917257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.779586</td>\n",
       "      <td>-0.885235</td>\n",
       "      <td>-0.654513</td>\n",
       "      <td>-0.185930</td>\n",
       "      <td>-0.462820</td>\n",
       "      <td>-0.079726</td>\n",
       "      <td>0.478409</td>\n",
       "      <td>0.296423</td>\n",
       "      <td>0.761742</td>\n",
       "      <td>0.362223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.239705</td>\n",
       "      <td>-1.245250</td>\n",
       "      <td>-0.929713</td>\n",
       "      <td>0.350711</td>\n",
       "      <td>0.067621</td>\n",
       "      <td>-0.576786</td>\n",
       "      <td>0.258883</td>\n",
       "      <td>0.597501</td>\n",
       "      <td>0.542174</td>\n",
       "      <td>0.105898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.438098</td>\n",
       "      <td>-0.014551</td>\n",
       "      <td>-0.324895</td>\n",
       "      <td>1.198067</td>\n",
       "      <td>-1.613589</td>\n",
       "      <td>-0.289867</td>\n",
       "      <td>-1.392326</td>\n",
       "      <td>-0.511372</td>\n",
       "      <td>-0.262235</td>\n",
       "      <td>-0.331464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.123491</td>\n",
       "      <td>5.063447</td>\n",
       "      <td>0.209638</td>\n",
       "      <td>0.614883</td>\n",
       "      <td>-0.085365</td>\n",
       "      <td>0.092426</td>\n",
       "      <td>0.558527</td>\n",
       "      <td>-0.485258</td>\n",
       "      <td>0.419050</td>\n",
       "      <td>-0.162114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.692517</td>\n",
       "      <td>-0.387207</td>\n",
       "      <td>1.585810</td>\n",
       "      <td>-0.821482</td>\n",
       "      <td>0.327681</td>\n",
       "      <td>0.095521</td>\n",
       "      <td>0.386481</td>\n",
       "      <td>0.181995</td>\n",
       "      <td>0.290930</td>\n",
       "      <td>0.129893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2.141782</td>\n",
       "      <td>-1.617599</td>\n",
       "      <td>-0.902444</td>\n",
       "      <td>-1.414973</td>\n",
       "      <td>0.404663</td>\n",
       "      <td>-0.152856</td>\n",
       "      <td>-1.000738</td>\n",
       "      <td>-0.559777</td>\n",
       "      <td>-0.066186</td>\n",
       "      <td>-0.136791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.316360</td>\n",
       "      <td>-0.022638</td>\n",
       "      <td>-0.722914</td>\n",
       "      <td>-1.403744</td>\n",
       "      <td>-0.617986</td>\n",
       "      <td>0.709270</td>\n",
       "      <td>0.295180</td>\n",
       "      <td>1.035913</td>\n",
       "      <td>-0.210943</td>\n",
       "      <td>-0.211891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.291747</td>\n",
       "      <td>-1.268354</td>\n",
       "      <td>-1.352191</td>\n",
       "      <td>-1.268271</td>\n",
       "      <td>-0.115264</td>\n",
       "      <td>-0.344346</td>\n",
       "      <td>-0.037749</td>\n",
       "      <td>-0.328800</td>\n",
       "      <td>-0.338828</td>\n",
       "      <td>0.045768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.021783</td>\n",
       "      <td>-0.273324</td>\n",
       "      <td>-1.056561</td>\n",
       "      <td>-0.080321</td>\n",
       "      <td>-1.154121</td>\n",
       "      <td>0.236616</td>\n",
       "      <td>1.530644</td>\n",
       "      <td>-0.514523</td>\n",
       "      <td>-0.637752</td>\n",
       "      <td>0.188482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.394024</td>\n",
       "      <td>3.277966</td>\n",
       "      <td>-0.292009</td>\n",
       "      <td>-0.647414</td>\n",
       "      <td>-0.621027</td>\n",
       "      <td>0.441710</td>\n",
       "      <td>0.013599</td>\n",
       "      <td>-0.617534</td>\n",
       "      <td>-0.025579</td>\n",
       "      <td>0.190396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-3.456337</td>\n",
       "      <td>-1.185622</td>\n",
       "      <td>3.667502</td>\n",
       "      <td>-0.507675</td>\n",
       "      <td>0.356034</td>\n",
       "      <td>1.101774</td>\n",
       "      <td>-0.056379</td>\n",
       "      <td>0.358090</td>\n",
       "      <td>-0.400006</td>\n",
       "      <td>-0.353515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.177622</td>\n",
       "      <td>-0.114896</td>\n",
       "      <td>-0.343979</td>\n",
       "      <td>1.126331</td>\n",
       "      <td>1.611014</td>\n",
       "      <td>-1.048859</td>\n",
       "      <td>0.410374</td>\n",
       "      <td>0.127281</td>\n",
       "      <td>-0.142061</td>\n",
       "      <td>-0.249013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.003550</td>\n",
       "      <td>2.139083</td>\n",
       "      <td>-0.322504</td>\n",
       "      <td>-0.397308</td>\n",
       "      <td>0.351041</td>\n",
       "      <td>-1.121693</td>\n",
       "      <td>0.200922</td>\n",
       "      <td>0.036825</td>\n",
       "      <td>0.019112</td>\n",
       "      <td>-0.742125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.093621</td>\n",
       "      <td>4.211884</td>\n",
       "      <td>0.237190</td>\n",
       "      <td>-0.222916</td>\n",
       "      <td>0.373531</td>\n",
       "      <td>0.037242</td>\n",
       "      <td>-1.106494</td>\n",
       "      <td>1.015406</td>\n",
       "      <td>-0.129065</td>\n",
       "      <td>0.425008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.165832</td>\n",
       "      <td>-1.605912</td>\n",
       "      <td>2.720420</td>\n",
       "      <td>-0.219895</td>\n",
       "      <td>-0.395025</td>\n",
       "      <td>-0.705684</td>\n",
       "      <td>0.195607</td>\n",
       "      <td>-0.367981</td>\n",
       "      <td>0.414869</td>\n",
       "      <td>-0.437946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-1.189840</td>\n",
       "      <td>-1.666167</td>\n",
       "      <td>-1.675454</td>\n",
       "      <td>-0.962103</td>\n",
       "      <td>0.190084</td>\n",
       "      <td>-0.187701</td>\n",
       "      <td>-0.501483</td>\n",
       "      <td>-0.191717</td>\n",
       "      <td>0.433305</td>\n",
       "      <td>0.213757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.624218</td>\n",
       "      <td>-1.822845</td>\n",
       "      <td>0.131416</td>\n",
       "      <td>1.791690</td>\n",
       "      <td>-1.190435</td>\n",
       "      <td>0.877449</td>\n",
       "      <td>-0.275524</td>\n",
       "      <td>0.320188</td>\n",
       "      <td>0.454152</td>\n",
       "      <td>-0.042135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.520321</td>\n",
       "      <td>-1.304031</td>\n",
       "      <td>-1.279476</td>\n",
       "      <td>1.204357</td>\n",
       "      <td>0.512605</td>\n",
       "      <td>-0.875542</td>\n",
       "      <td>0.082752</td>\n",
       "      <td>0.506641</td>\n",
       "      <td>-0.587545</td>\n",
       "      <td>0.057018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-2.311141</td>\n",
       "      <td>-0.288265</td>\n",
       "      <td>0.059420</td>\n",
       "      <td>0.708594</td>\n",
       "      <td>-0.318337</td>\n",
       "      <td>0.489120</td>\n",
       "      <td>0.181326</td>\n",
       "      <td>0.400682</td>\n",
       "      <td>-0.449099</td>\n",
       "      <td>0.146265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pc_0      pc_1      pc_2      pc_3      pc_4      pc_5      pc_6  \\\n",
       "0   2.775385 -0.512451 -1.398603  0.766013  1.904395  2.087560 -0.067536   \n",
       "1   2.742665 -0.478032  2.643861  0.371387  0.475300 -0.785631 -0.154473   \n",
       "2  -0.779586 -0.885235 -0.654513 -0.185930 -0.462820 -0.079726  0.478409   \n",
       "3  -0.239705 -1.245250 -0.929713  0.350711  0.067621 -0.576786  0.258883   \n",
       "4   2.438098 -0.014551 -0.324895  1.198067 -1.613589 -0.289867 -1.392326   \n",
       "5  -1.123491  5.063447  0.209638  0.614883 -0.085365  0.092426  0.558527   \n",
       "6   0.692517 -0.387207  1.585810 -0.821482  0.327681  0.095521  0.386481   \n",
       "7  -2.141782 -1.617599 -0.902444 -1.414973  0.404663 -0.152856 -1.000738   \n",
       "8   5.316360 -0.022638 -0.722914 -1.403744 -0.617986  0.709270  0.295180   \n",
       "9  -1.291747 -1.268354 -1.352191 -1.268271 -0.115264 -0.344346 -0.037749   \n",
       "10  0.021783 -0.273324 -1.056561 -0.080321 -1.154121  0.236616  1.530644   \n",
       "11 -1.394024  3.277966 -0.292009 -0.647414 -0.621027  0.441710  0.013599   \n",
       "12 -3.456337 -1.185622  3.667502 -0.507675  0.356034  1.101774 -0.056379   \n",
       "13 -0.177622 -0.114896 -0.343979  1.126331  1.611014 -1.048859  0.410374   \n",
       "14  0.003550  2.139083 -0.322504 -0.397308  0.351041 -1.121693  0.200922   \n",
       "15  0.093621  4.211884  0.237190 -0.222916  0.373531  0.037242 -1.106494   \n",
       "16  2.165832 -1.605912  2.720420 -0.219895 -0.395025 -0.705684  0.195607   \n",
       "17 -1.189840 -1.666167 -1.675454 -0.962103  0.190084 -0.187701 -0.501483   \n",
       "18 -1.624218 -1.822845  0.131416  1.791690 -1.190435  0.877449 -0.275524   \n",
       "19 -0.520321 -1.304031 -1.279476  1.204357  0.512605 -0.875542  0.082752   \n",
       "20 -2.311141 -0.288265  0.059420  0.708594 -0.318337  0.489120  0.181326   \n",
       "\n",
       "        pc_7      pc_8      pc_9  \n",
       "0  -0.661068  0.120825 -0.114971  \n",
       "1  -0.638914 -0.206860  0.917257  \n",
       "2   0.296423  0.761742  0.362223  \n",
       "3   0.597501  0.542174  0.105898  \n",
       "4  -0.511372 -0.262235 -0.331464  \n",
       "5  -0.485258  0.419050 -0.162114  \n",
       "6   0.181995  0.290930  0.129893  \n",
       "7  -0.559777 -0.066186 -0.136791  \n",
       "8   1.035913 -0.210943 -0.211891  \n",
       "9  -0.328800 -0.338828  0.045768  \n",
       "10 -0.514523 -0.637752  0.188482  \n",
       "11 -0.617534 -0.025579  0.190396  \n",
       "12  0.358090 -0.400006 -0.353515  \n",
       "13  0.127281 -0.142061 -0.249013  \n",
       "14  0.036825  0.019112 -0.742125  \n",
       "15  1.015406 -0.129065  0.425008  \n",
       "16 -0.367981  0.414869 -0.437946  \n",
       "17 -0.191717  0.433305  0.213757  \n",
       "18  0.320188  0.454152 -0.042135  \n",
       "19  0.506641 -0.587545  0.057018  \n",
       "20  0.400682 -0.449099  0.146265  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: [Errno 2] No such file or directory: 'D:\\\\project\\\\hadoop-3.4.0\\\\share\\\\doc\\\\hadoop\\\\hadoop-yarn\\\\hadoop-yarn-server\\\\hadoop-yarn-server-resourcemanager\\\\apidocs\\\\org\\\\apache\\\\hadoop\\\\yarn\\\\server\\\\resourcemanager\\\\monitor\\\\capacity\\\\class-use\\\\ProportionalCapacityPreemptionPolicy.IntraQueuePreemptionOrderPolicy.html'\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "def extract_tar_gz(file_path, extract_path):\n",
    "    try:\n",
    "        # Open the .tar.gz file\n",
    "        with gzip.open(file_path, 'rb') as f_in:\n",
    "            # Open the .tar file\n",
    "            with tarfile.open(fileobj=f_in, mode='r') as tar:\n",
    "                # Extract the contents to the specified path\n",
    "                tar.extractall(path=extract_path)\n",
    "        print(\"Extraction completed successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "file_path = 'hadoop-3.4.0.tar.gz'  # Replace 'hadoop-3.4.0.tar.gz' with the path to your file\n",
    "extract_path = 'D:/project/'  # Replace 'D:/project/' with your desired extraction path\n",
    "\n",
    "# Ensure the extraction directory exists\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "extract_tar_gz(file_path, extract_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import pymongo\n",
    "\n",
    "# # Function to connect to MongoDB\n",
    "# def connect_to_mongodb():\n",
    "#     # Connect to MongoDB\n",
    "#     client = pymongo.MongoClient(\"mongodb://localhost:27017/\")  # Replace with your MongoDB connection string\n",
    "#     # Create or select a database\n",
    "#     db = client[\"music_features_database\"]\n",
    "#     return db\n",
    "\n",
    "# # Path to the CSV file containing transformed data\n",
    "# csv_file = \"reduced_audio_features.csv\"\n",
    "\n",
    "# # Read the CSV file into a DataFrame\n",
    "# transformed_data_df = pd.read_csv(csv_file)\n",
    "\n",
    "# # Connect to MongoDB\n",
    "# db = connect_to_mongodb()\n",
    "\n",
    "# # Convert DataFrame to dictionary\n",
    "# transformed_data_dict = transformed_data_df.to_dict(orient=\"records\")\n",
    "\n",
    "# # Insert data into MongoDB collection\n",
    "# collection_name = \"audio_features_collection\"\n",
    "# collection = db[collection_name]\n",
    "# collection.insert_many(transformed_data_dict)\n",
    "\n",
    "# print(\"Transformed data has been successfully stored in MongoDB.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Transformed data has been successfully stored in MongoDB.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pymongo\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Function to extract audio features\n",
    "def extract_features(audio_file, sr=22050, n_mfcc=13):\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_file, sr=sr)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        mfcc_mean = np.mean(mfcc, axis=1)\n",
    "        return mfcc_mean\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting features from {audio_file}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to normalize features\n",
    "def normalize_features(features):\n",
    "    try:\n",
    "        normalized_features = (features - features.min()) / (features.max() - features.min())\n",
    "        return normalized_features\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error normalizing features: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to standardize features\n",
    "def standardize_features(features):\n",
    "    try:\n",
    "        scaler = StandardScaler()\n",
    "        standardized_features = scaler.fit_transform(features)\n",
    "        return standardized_features\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error standardizing features: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to connect to MongoDB\n",
    "def connect_to_mongodb(uri, db_name):\n",
    "    try:\n",
    "        client = pymongo.MongoClient(uri)\n",
    "        db = client[db_name]\n",
    "        return db\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error connecting to MongoDB: {e}\")\n",
    "        return None\n",
    "\n",
    "# Main function to process audio files and store data in MongoDB\n",
    "def process_audio_files(audio_folder, mongodb_uri, db_name, output_csv):\n",
    "    try:\n",
    "        features_df = pd.DataFrame()\n",
    "        for file in os.listdir(audio_folder):\n",
    "            if file.endswith(\".mp3\"):\n",
    "                audio_file = os.path.join(audio_folder, file)\n",
    "                mfcc_features = extract_features(audio_file)\n",
    "                if mfcc_features is not None:\n",
    "                    df = pd.DataFrame([mfcc_features], columns=[f\"mfcc_{i}\" for i in range(len(mfcc_features))])\n",
    "                    features_df = pd.concat([features_df, df], ignore_index=True)\n",
    "\n",
    "        if features_df.empty:\n",
    "            logger.error(\"No audio features extracted.\")\n",
    "            return\n",
    "\n",
    "        normalized_features = normalize_features(features_df)\n",
    "        if normalized_features is None:\n",
    "            return\n",
    "\n",
    "        standardized_features = standardize_features(normalized_features)\n",
    "        if standardized_features is None:\n",
    "            return\n",
    "\n",
    "        pca = PCA(n_components=10)\n",
    "        reduced_features = pca.fit_transform(standardized_features)\n",
    "        reduced_features_df = pd.DataFrame(reduced_features, columns=[f\"pc_{i}\" for i in range(reduced_features.shape[1])])\n",
    "        reduced_features_df.to_csv(output_csv, index=False)\n",
    "\n",
    "        db = connect_to_mongodb(mongodb_uri, db_name)\n",
    "        if db is not None:\n",
    "            transformed_data_dict = reduced_features_df.to_dict(orient=\"records\")\n",
    "            collection_name = \"audio_features_collectionn\"\n",
    "            collection = db[collection_name]\n",
    "            collection.insert_many(transformed_data_dict)\n",
    "            logger.info(\"Transformed data has been successfully stored in MongoDB.\")\n",
    "        else:\n",
    "            logger.error(\"Failed to connect to MongoDB.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during processing: {e}\")\n",
    "\n",
    "# Set parameters\n",
    "audio_folder = \"audio\"\n",
    "mongodb_uri = \"mongodb://localhost:27017/\"\n",
    "db_name = \"music_features_databasee\"\n",
    "output_csv = \"reduced_audio_features.csv\"\n",
    "\n",
    "# Process audio files and store data in MongoDB\n",
    "process_audio_files(audio_folder, mongodb_uri, db_name, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pymongo.serverSelection:{\"message\": \"Waiting for suitable server to become available\", \"selector\": \"Primary()\", \"operation\": \"listDatabases\", \"topologyDescription\": \"<TopologyDescription id: 663d7a0573acb8a1044114cb, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>\", \"clientId\": {\"$oid\": \"663d7a0573acb8a1044114cb\"}, \"remainingTimeMS\": 30}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available databases:\n",
      "['admin', 'config', 'local', 'music_features_databasee']\n",
      "Collections in music_features_database:\n",
      "[]\n",
      "Connection successful!\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "\n",
    "# MongoDB connection URI\n",
    "mongo_uri = \"mongodb://localhost:27017/\"\n",
    "\n",
    "try:\n",
    "    # Connect to MongoDB\n",
    "    client = pymongo.MongoClient(mongo_uri)\n",
    "    \n",
    "    # List available databases\n",
    "    print(\"Available databases:\")\n",
    "    print(client.list_database_names())\n",
    "    \n",
    "    # List collections in a specific database\n",
    "    db = client[\"music_features_database\"]\n",
    "    print(\"Collections in music_features_database:\")\n",
    "    print(db.list_collection_names())\n",
    "    \n",
    "    # Close connection\n",
    "    client.close()\n",
    "    \n",
    "    print(\"Connection successful!\")\n",
    "except Exception as e:\n",
    "    print(\"Connection error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Recommendation Model with Apache Spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RegressionEvaluator\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize Spark session\u001b[39;00m\n\u001b[0;32m      6\u001b[0m spark \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMusicRecommendationModelTraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m----> 8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Load transformed audio features from MongoDB or CSV file\u001b[39;00m\n\u001b[0;32m     11\u001b[0m transformed_data \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmongo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmongodb://localhost:27017/music_features_databasee/audio_features_collectionn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyspark\\sql\\session.py:497\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    495\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[0;32m    500\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyspark\\context.py:515\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[1;34m(cls, conf)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 515\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyspark\\context.py:201\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    199\u001b[0m     )\n\u001b[1;32m--> 201\u001b[0m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[0;32m    204\u001b[0m         master,\n\u001b[0;32m    205\u001b[0m         appName,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    215\u001b[0m         memory_profiler_cls,\n\u001b[0;32m    216\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyspark\\context.py:436\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_gateway:\n\u001b[1;32m--> 436\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_gateway \u001b[38;5;241m=\u001b[39m gateway \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mlaunch_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_gateway\u001b[38;5;241m.\u001b[39mjvm\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyspark\\java_gateway.py:100\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf, popen_kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m     proc \u001b[38;5;241m=\u001b[39m Popen(command, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpopen_kwargs)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# preexec_fn not supported on Windows\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     proc \u001b[38;5;241m=\u001b[39m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Wait for the file to appear, or for the process to exit, whichever happens first.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpoll() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(conn_info_file):\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1034\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mCreateProcess(executable, args,\n\u001b[0;32m   1539\u001b[0m                              \u001b[38;5;66;03m# no special security\u001b[39;00m\n\u001b[0;32m   1540\u001b[0m                              \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1541\u001b[0m                              \u001b[38;5;28mint\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m close_fds),\n\u001b[0;32m   1542\u001b[0m                              creationflags,\n\u001b[0;32m   1543\u001b[0m                              env,\n\u001b[0;32m   1544\u001b[0m                              cwd,\n\u001b[0;32m   1545\u001b[0m                              startupinfo)\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1554\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1555\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "#if spark works\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MusicRecommendationModelTraining\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load transformed audio features from MongoDB or CSV file\n",
    "transformed_data = spark.read.format(\"mongo\").load(\"mongodb://localhost:27017/music_features_databasee/audio_features_collectionn\")\n",
    "# Example: transformed_data = spark.read.csv(\"reduced_audio_features.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "(training_data, test_data) = transformed_data.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Train ALS model\n",
    "als = ALS(maxIter=10, regParam=0.01, userCol=\"user_id\", itemCol=\"item_id\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "model = als.fit(training_data)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) =\", rmse)\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring Collaborative Filtering and ANN Algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if spark works\n",
    "\n",
    "# Collaborative Filtering\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CollaborativeFilteringExample\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load transformed audio features from MongoDB or CSV file\n",
    "transformed_data = spark.read.format(\"mongo\").load(\"mongodb://localhost:27017/music_features_database.reduced_audio_features_collection\")\n",
    "# Example: transformed_data = spark.read.csv(\"reduced_audio_features.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "(training_data, test_data) = transformed_data.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Train ALS model for collaborative filtering\n",
    "als = ALS(maxIter=10, regParam=0.01, userCol=\"user_id\", itemCol=\"item_id\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "model = als.fit(training_data)\n",
    "\n",
    "# ANN - Approximate Nearest Neighbours\n",
    "# You can use a library like Annoy, Faiss, or Hnswlib for ANN implementation\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the Model with Various Metrics and Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if spark works\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ModelEvaluationAndHyperparameterTuning\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load transformed audio features from MongoDB or CSV file\n",
    "transformed_data = spark.read.format(\"mongo\").load(\"mongodb://localhost:27017/music_features_database.reduced_audio_features_collection\")\n",
    "# Example: transformed_data = spark.read.csv(\"reduced_audio_features.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "(training_data, test_data) = transformed_data.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Define ALS model\n",
    "als = ALS(userCol=\"user_id\", itemCol=\"item_id\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(als.rank, [10, 20, 30]) \\\n",
    "    .addGrid(als.maxIter, [10, 20, 30]) \\\n",
    "    .addGrid(als.regParam, [0.01, 0.1, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "# Define evaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "# Define cross-validator\n",
    "cross_validator = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "cv_model = cross_validator.fit(training_data)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = cv_model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) =\", rmse)\n",
    "\n",
    "# Best model parameters\n",
    "best_model = cv_model.bestModel\n",
    "print(\"Best Rank =\", best_model.rank)\n",
    "print(\"Best Max Iter =\", best_model._java_obj.parent().getMaxIter())\n",
    "print(\"Best Regularization Parameter =\", best_model._java_obj.parent().getRegParam())\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deployment - Cell 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flask'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflask\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Flask, request, jsonify\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkafka\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KafkaProducer\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize Flask app\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'flask'"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALSModel\n",
    "from flask import Flask, render_template, request\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the trained ALS model\n",
    "saved_model_path = \"music_recommendation_model\"\n",
    "trained_model = ALSModel.load(saved_model_path)\n",
    "\n",
    "# Initialize Kafka producer\n",
    "producer = KafkaProducer(bootstrap_servers='localhost:9092')\n",
    "\n",
    "# Route for home page\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "# Route for generating recommendations\n",
    "@app.route('/recommend', methods=['POST'])\n",
    "def recommend():\n",
    "    # Extract user input\n",
    "    user_id = request.form.get('user_id')\n",
    "    num_recommendations = int(request.form.get('num_recommendations'))\n",
    "\n",
    "    # Generate recommendations using the trained model\n",
    "    recommendations = trained_model.recommendForUserSubset(spark.createDataFrame([(user_id,)], [\"user_id\"]), num_recommendations)\n",
    "\n",
    "    # Send recommendations to Kafka topic\n",
    "    for row in recommendations.collect():\n",
    "        for rec in row.recommendations:\n",
    "            producer.send('recommendations_topic', key=str(row.user_id).encode(), value=str(rec.item_id).encode())\n",
    "\n",
    "    # Return recommendations to user interface\n",
    "    return render_template('recommendations.html', recommendations=recommendations)\n",
    "\n",
    "# Route for receiving user activity\n",
    "@app.route('/user_activity', methods=['POST'])\n",
    "def user_activity():\n",
    "    # Extract user activity\n",
    "    user_id = request.form.get('user_id')\n",
    "    item_id = request.form.get('item_id')\n",
    "\n",
    "    # Send user activity to Kafka topic\n",
    "    producer.send('user_activity_topic', key=user_id.encode(), value=item_id.encode())\n",
    "\n",
    "    return 'User activity sent to Kafka topic'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
