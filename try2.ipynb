{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pymongo.serverSelection:{\"message\": \"Waiting for suitable server to become available\", \"selector\": \"<function writable_server_selector at 0x000001FE205B4EA0>\", \"operation\": \"insert\", \"operationId\": -609045504, \"topologyDescription\": \"<TopologyDescription id: 663f8652ac51b34e32a1b09f, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>\", \"clientId\": {\"$oid\": \"663f8652ac51b34e32a1b09f\"}, \"remainingTimeMS\": 30}\n",
      "INFO:__main__:Transformed data has been successfully stored in MongoDB.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pymongo\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Function to extract audio features\n",
    "def extract_features(audio_file, sr=22050, n_mfcc=13):\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_file, sr=sr)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        mfcc_mean = np.mean(mfcc, axis=1)\n",
    "        return mfcc_mean\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting features from {audio_file}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to normalize features\n",
    "def normalize_features(features):\n",
    "    try:\n",
    "        normalized_features = (features - features.min()) / (features.max() - features.min())\n",
    "        return normalized_features\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error normalizing features: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to standardize features\n",
    "def standardize_features(features):\n",
    "    try:\n",
    "        scaler = StandardScaler()\n",
    "        standardized_features = scaler.fit_transform(features)\n",
    "        return standardized_features\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error standardizing features: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to connect to MongoDB\n",
    "def connect_to_mongodb(uri, db_name):\n",
    "    try:\n",
    "        client = pymongo.MongoClient(uri)\n",
    "        db = client[db_name]\n",
    "        return db\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error connecting to MongoDB: {e}\")\n",
    "        return None\n",
    "\n",
    "# Main function to process audio files and store data in MongoDB\n",
    "def process_audio_files(audio_folder, mongodb_uri, db_name, output_csv):\n",
    "    try:\n",
    "        features_df = pd.DataFrame()\n",
    "        for file in os.listdir(audio_folder):\n",
    "            if file.endswith(\".mp3\"):\n",
    "                audio_file = os.path.join(audio_folder, file)\n",
    "                mfcc_features = extract_features(audio_file)\n",
    "                if mfcc_features is not None:\n",
    "                    df = pd.DataFrame([mfcc_features], columns=[f\"mfcc_{i}\" for i in range(len(mfcc_features))])\n",
    "                    features_df = pd.concat([features_df, df], ignore_index=True)\n",
    "\n",
    "        if features_df.empty:\n",
    "            logger.error(\"No audio features extracted.\")\n",
    "            return\n",
    "\n",
    "        normalized_features = normalize_features(features_df)\n",
    "        if normalized_features is None:\n",
    "            return\n",
    "\n",
    "        standardized_features = standardize_features(normalized_features)\n",
    "        if standardized_features is None:\n",
    "            return\n",
    "\n",
    "        pca = PCA(n_components=10)\n",
    "        reduced_features = pca.fit_transform(standardized_features)\n",
    "        reduced_features_df = pd.DataFrame(reduced_features, columns=[f\"pc_{i}\" for i in range(reduced_features.shape[1])])\n",
    "        reduced_features_df.to_csv(output_csv, index=False)\n",
    "\n",
    "        db = connect_to_mongodb(mongodb_uri, db_name)\n",
    "        if db is not None:\n",
    "            transformed_data_dict = reduced_features_df.to_dict(orient=\"records\")\n",
    "            collection_name = \"audio_features_collectionn\"\n",
    "            collection = db[collection_name]\n",
    "            collection.insert_many(transformed_data_dict)\n",
    "            logger.info(\"Transformed data has been successfully stored in MongoDB.\")\n",
    "        else:\n",
    "            logger.error(\"Failed to connect to MongoDB.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during processing: {e}\")\n",
    "\n",
    "# Set parameters\n",
    "audio_folder = \"audio\"\n",
    "mongodb_uri = \"mongodb://localhost:27017/\"\n",
    "db_name = \"music_features_databasee\"\n",
    "output_csv = \"reduced_audio_features111.csv\"\n",
    "\n",
    "# Process audio files and store data in MongoDB\n",
    "process_audio_files(audio_folder, mongodb_uri, db_name, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        pc_0      pc_1      pc_2      pc_3      pc_4      pc_5      pc_6  \\\n",
      "0   2.775385 -0.512451 -1.398603  0.766013  1.904395  2.087560 -0.067536   \n",
      "1   2.742665 -0.478032  2.643861  0.371387  0.475300 -0.785631 -0.154473   \n",
      "2  -0.779586 -0.885235 -0.654513 -0.185930 -0.462820 -0.079726  0.478409   \n",
      "3  -0.239705 -1.245250 -0.929713  0.350711  0.067621 -0.576786  0.258883   \n",
      "4   2.438098 -0.014551 -0.324895  1.198067 -1.613589 -0.289867 -1.392326   \n",
      "5  -1.123491  5.063447  0.209638  0.614883 -0.085365  0.092426  0.558527   \n",
      "6   0.692517 -0.387207  1.585810 -0.821483  0.327681  0.095521  0.386481   \n",
      "7  -2.141782 -1.617599 -0.902443 -1.414972  0.404663 -0.152856 -1.000738   \n",
      "8   5.316360 -0.022638 -0.722914 -1.403744 -0.617986  0.709271  0.295180   \n",
      "9  -1.291747 -1.268354 -1.352191 -1.268271 -0.115264 -0.344346 -0.037749   \n",
      "10  0.021783 -0.273324 -1.056561 -0.080321 -1.154121  0.236616  1.530644   \n",
      "11 -1.394024  3.277966 -0.292009 -0.647414 -0.621027  0.441710  0.013599   \n",
      "12 -3.456337 -1.185622  3.667502 -0.507675  0.356034  1.101774 -0.056379   \n",
      "13 -0.177622 -0.114896 -0.343979  1.126331  1.611014 -1.048859  0.410374   \n",
      "14  0.003550  2.139083 -0.322504 -0.397308  0.351041 -1.121693  0.200922   \n",
      "15  0.093621  4.211885  0.237190 -0.222916  0.373531  0.037242 -1.106494   \n",
      "16  2.165832 -1.605912  2.720420 -0.219895 -0.395025 -0.705684  0.195607   \n",
      "17 -1.189840 -1.666167 -1.675455 -0.962103  0.190084 -0.187701 -0.501483   \n",
      "18 -1.624219 -1.822845  0.131416  1.791690 -1.190435  0.877449 -0.275524   \n",
      "19 -0.520321 -1.304031 -1.279476  1.204357  0.512605 -0.875541  0.082752   \n",
      "20 -2.311141 -0.288265  0.059420  0.708594 -0.318337  0.489120  0.181326   \n",
      "\n",
      "        pc_7      pc_8      pc_9  \n",
      "0  -0.661068  0.120825 -0.114971  \n",
      "1  -0.638914 -0.206860  0.917257  \n",
      "2   0.296423  0.761742  0.362223  \n",
      "3   0.597501  0.542174  0.105898  \n",
      "4  -0.511372 -0.262235 -0.331464  \n",
      "5  -0.485258  0.419050 -0.162114  \n",
      "6   0.181995  0.290930  0.129893  \n",
      "7  -0.559777 -0.066186 -0.136791  \n",
      "8   1.035913 -0.210943 -0.211891  \n",
      "9  -0.328800 -0.338828  0.045768  \n",
      "10 -0.514523 -0.637752  0.188482  \n",
      "11 -0.617534 -0.025579  0.190396  \n",
      "12  0.358090 -0.400006 -0.353515  \n",
      "13  0.127280 -0.142061 -0.249013  \n",
      "14  0.036825  0.019112 -0.742125  \n",
      "15  1.015407 -0.129065  0.425008  \n",
      "16 -0.367981  0.414869 -0.437946  \n",
      "17 -0.191717  0.433305  0.213757  \n",
      "18  0.320188  0.454152 -0.042135  \n",
      "19  0.506641 -0.587545  0.057018  \n",
      "20  0.400682 -0.449099  0.146265  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'path_to_your_csv_file' with the actual path to your CSV file\n",
    "csv_file_path = 'reduced_audio_features111.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pymongo.serverSelection:{\"message\": \"Waiting for suitable server to become available\", \"selector\": \"Primary()\", \"operation\": \"listDatabases\", \"topologyDescription\": \"<TopologyDescription id: 663f86bcac51b34e32a1b0b5, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>\", \"clientId\": {\"$oid\": \"663f86bcac51b34e32a1b0b5\"}, \"remainingTimeMS\": 30}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available databases:\n",
      "['admin', 'amitdb', 'config', 'local', 'music_features_databasee']\n",
      "Collections in music_features_database:\n",
      "[]\n",
      "Connection successful!\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "\n",
    "# MongoDB connection URI\n",
    "mongo_uri = \"mongodb://localhost:27017/\"\n",
    "\n",
    "try:\n",
    "    # Connect to MongoDB\n",
    "    client = pymongo.MongoClient(mongo_uri)\n",
    "    \n",
    "    # List available databases\n",
    "    print(\"Available databases:\")\n",
    "    print(client.list_database_names())\n",
    "    \n",
    "    # List collections in a specific database\n",
    "    db = client[\"music_features_database\"]\n",
    "    print(\"Collections in music_features_database:\")\n",
    "    print(db.list_collection_names())\n",
    "    \n",
    "    # Close connection\n",
    "    client.close()\n",
    "    \n",
    "    print(\"Connection successful!\")\n",
    "except Exception as e:\n",
    "    print(\"Connection error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bilal\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\dask_ml\\model_selection\\_split.py:464: FutureWarning: The default value for 'shuffle' must be specified when splitting DataFrames. In the future DataFrames will automatically be shuffled within blocks prior to splitting. Specify 'shuffle=True' to adopt the future behavior now, or 'shuffle=False' to retain the previous behavior.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexing.py:1714\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1713\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1716\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:4153\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   4144\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4145\u001b[0m \u001b[38;5;124;03mInternal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   4146\u001b[0m \u001b[38;5;124;03mattribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4151\u001b[0m \u001b[38;5;124;03mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   4152\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 4153\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4154\u001b[0m \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[0;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[0;32m   4131\u001b[0m     )\n\u001b[1;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4135\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4140\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:891\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    890\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[1;32m--> 891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_convert_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexers\\utils.py:282\u001b[0m, in \u001b[0;36mmaybe_convert_indices\u001b[1;34m(indices, n, verify)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m--> 282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indices\n",
      "\u001b[1;31mIndexError\u001b[0m: indices are out-of-bounds",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m nearest_neighbors_indices \u001b[38;5;241m=\u001b[39m collaborative_filtering_model\u001b[38;5;241m.\u001b[39mkneighbors(X_test\u001b[38;5;241m.\u001b[39mcompute())[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     21\u001b[0m original_data_points \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m---> 22\u001b[0m nearest_neighbors \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_data_points\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnearest_neighbors_indices\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     23\u001b[0m cosine_similarity \u001b[38;5;241m=\u001b[39m (nearest_neighbors\u001b[38;5;241m.\u001b[39mdot(original_data_points\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;241m/\u001b[39m\n\u001b[0;32m     24\u001b[0m                      (nearest_neighbors\u001b[38;5;241m.\u001b[39mnorm() \u001b[38;5;241m*\u001b[39m original_data_points\u001b[38;5;241m.\u001b[39mnorm(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Cosine Similarity for Collaborative Filtering:\u001b[39m\u001b[38;5;124m\"\u001b[39m, cosine_similarity\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mcompute())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexing.py:1743\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1741\u001b[0m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_list_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1747\u001b[0m     key \u001b[38;5;241m=\u001b[39m item_from_zerodim(key)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexing.py:1717\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1714\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1716\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n\u001b[1;32m-> 1717\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional indexers are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from dask_ml.metrics import mean_squared_error\n",
    "from dask_ml.model_selection import train_test_split  # Import train_test_split function\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Step 1: Load Data from CSV using Dask\n",
    "df = dd.read_csv('reduced_audio_features111.csv')\n",
    "\n",
    "# Step 2: Split Data into Training and Testing Sets\n",
    "X_train, X_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Train Collaborative Filtering Model using NearestNeighbors\n",
    "collaborative_filtering_model = NearestNeighbors(n_neighbors=10, algorithm='auto', metric='cosine')\n",
    "collaborative_filtering_model.fit(X_train.compute())\n",
    "\n",
    "# Step 4: Evaluate Collaborative Filtering Model\n",
    "nearest_neighbors_indices = collaborative_filtering_model.kneighbors(X_test.compute())[1]\n",
    "original_data_points = X_test.compute()\n",
    "nearest_neighbors = original_data_points.iloc[nearest_neighbors_indices]\n",
    "cosine_similarity = (nearest_neighbors.dot(original_data_points.T) /\n",
    "                     (nearest_neighbors.norm() * original_data_points.norm(axis=1)))\n",
    "print(\"Average Cosine Similarity for Collaborative Filtering:\", cosine_similarity.mean().compute())\n",
    "\n",
    "# Step 5: Train Neural Network Model\n",
    "# Define the neural network model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, input_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Convert Dask DataFrame to NumPy arrays\n",
    "X_train_array = X_train.compute().to_numpy()\n",
    "X_test_array = X_test.compute().to_numpy()\n",
    "\n",
    "# Define and train the neural network model\n",
    "input_size = X_train_array.shape[1]\n",
    "hidden_size = 64\n",
    "model = NeuralNetwork(input_size, hidden_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    inputs = torch.autograd.Variable(torch.Tensor(X_train_array).float())\n",
    "    targets = torch.autograd.Variable(torch.Tensor(X_train_array).float())\n",
    "    optimizer.zero_grad()\n",
    "    out = model(inputs)\n",
    "    loss = criterion(out, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Step 6: Evaluate Neural Network Model\n",
    "inputs = torch.autograd.Variable(torch.Tensor(X_test_array).float())\n",
    "predicted = model(inputs).detach().numpy()\n",
    "mse_nn = mean_squared_error(X_test_array, predicted)\n",
    "print(\"Mean Squared Error for Neural Network Model:\", mse_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For collaborative filtering approach\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# For neural network-based approach\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a CSV file 'normalized_audio_features.csv'\n",
    "# Load the data\n",
    "data = pd.read_csv('normalized_audio_features.csv')\n",
    "\n",
    "# Split data into features and labels\n",
    "X = data.drop(columns=['target_column'])  # Features\n",
    "y = data['target_column']  # Labels\n",
    "\n",
    "# Initialize and train the model\n",
    "# Example for collaborative filtering\n",
    "cf_model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "cf_model.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example hyperparameter tuning for collaborative filtering\n",
    "params = {\n",
    "    'n_neighbors': [5, 10, 15],\n",
    "    'algorithm': ['ball_tree', 'kd_tree'],\n",
    "    'leaf_size': [20, 30, 40],\n",
    "    'metric': ['cosine', 'euclidean']\n",
    "}\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "grid_search = GridSearchCV(cf_model, params, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search.fit(X_train)\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have test data X_test\n",
    "# Predict recommendations for test data\n",
    "distances, indices = cf_model.kneighbors(X_test)\n",
    "\n",
    "# Evaluate model performance using appropriate metrics\n",
    "# Example:\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
